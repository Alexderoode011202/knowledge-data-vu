{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge and Data: Practical Assignment 3 \n",
    "## RDF Data, RDFS knowledge and inferencing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR NAME: Alex de Roode\n",
    "\n",
    "YOUR VUNetID: aro241\n",
    "\n",
    "*(If you do not provide your name and VUNetID we will not accept your submission).* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning objectives\n",
    "\n",
    "At the end of this exercise you should be able to:\n",
    "\n",
    "1. Access local an external data via SPARQL both from within a python programming environment and stand-alone with a GUI, such as [YASGUI](https://yasgui.triply.cc/), and this way integrate data from different sources  \n",
    "2. Model your own first knowledge base, in this case an RDF Schema knowledge graph\n",
    "3. Implement inference rules "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow this Notebook step-by-step. \n",
    "\n",
    "Of course, you can do the exercises in any Programming Editor of your liking. \n",
    "But you do not have to. Feel free to simply write code in the Notebook. When \n",
    "everythink is filled in and works, safe the Notebook and submit it \n",
    "as a Jupyter Notebook, i.e. with an ipynb extension. Please use as name of the \n",
    "Notebook your studentID+Assignment3.ipynb.  \n",
    "\n",
    "\n",
    "We will not evaluate the programming style of your solutions. Yet we do look whether your solutions suggests an understanding, and whether they yield the correct output.\n",
    "\n",
    "Note that all notebooks will automatically be checked for plagiarism: while similar answers can be expected, it is not allowed to directly copy the solutions from fellow students or TAs, or from the examples discussed during the lectures. Similarly, sharing your solutions with your peers is not allowed.\n",
    "\n",
    "**IMPORTANT: Submit this notebook after finishing the assignment. It is not necessary to submit the created turtle files**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you start, you need to:\n",
    "\n",
    "- **Install the *rdflib* Python package:** *pip install rdflib* (should already be installed from the previous assignment)\n",
    "- **Install the *SPARQLWrapper* Python package:** *pip install SPARQLWrapper*\n",
    "- **Install the free edition of the GraphDB Triplestore:** please follow this short [GraphDB tutorial](https://github.com/ucds-vu/knowledge-data-vu/blob/master/Tutorials/Preliminaries/tutorial-GraphDB.md). \n",
    "\n",
    "Then, add the file example-from-slides.ttl to a newly created database, say called assignment-3. \n",
    "\n",
    "**Note that you should have an active internet connection to run the code in this notebook. Also, if, for some external reason (ie internet and/or system issues), you cannot access the SPARQL endpoint, then report this to a TA as soon as possible!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting SPARQLWrapper\n",
      "  Downloading SPARQLWrapper-2.0.0-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: rdflib>=6.1.1 in /home/alex/Downloads/Downloads/envs/newest_version/lib/python3.11/site-packages (from SPARQLWrapper) (7.0.0)\n",
      "Requirement already satisfied: isodate<0.7.0,>=0.6.0 in /home/alex/Downloads/Downloads/envs/newest_version/lib/python3.11/site-packages (from rdflib>=6.1.1->SPARQLWrapper) (0.6.1)\n",
      "Requirement already satisfied: pyparsing<4,>=2.1.0 in /home/alex/Downloads/Downloads/envs/newest_version/lib/python3.11/site-packages (from rdflib>=6.1.1->SPARQLWrapper) (3.0.9)\n",
      "Requirement already satisfied: six in /home/alex/Downloads/Downloads/envs/newest_version/lib/python3.11/site-packages (from isodate<0.7.0,>=0.6.0->rdflib>=6.1.1->SPARQLWrapper) (1.16.0)\n",
      "Installing collected packages: SPARQLWrapper\n",
      "Successfully installed SPARQLWrapper-2.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# install library\n",
    "%pip install SPARQLWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: (35 points) Integrate Local and External Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can integrate SPARQL queries into your Python code by using the *RDFLib* and *SPARQLWrapper* libraries. \n",
    "\n",
    "The following code accesses the DBPedia knowledge graph using its SPARQL endpoint, and returns the result of the SPARQL query requesting all the labels asserted to Amsterdam (test it!)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amsterdam\n",
      "أمستردام\n",
      "Amsterdam\n",
      "Amsterdam\n",
      "Amsterdam\n",
      "Άμστερνταμ\n",
      "Amsterdamo\n",
      "Ámsterdam\n",
      "Amsterdam\n",
      "Amstardam\n",
      "Amsterdam\n",
      "Amsterdam\n",
      "Amsterdam\n",
      "암스테르담\n",
      "アムステルダム\n",
      "Amsterdam\n",
      "Amsterdam\n",
      "Амстердам\n",
      "Amesterdão\n",
      "Amsterdam\n",
      "Амстердам\n",
      "阿姆斯特丹\n"
     ]
    }
   ],
   "source": [
    "# This code only works if you are online.\n",
    "# If, for some reason, you cannot get this to work, then please contact a TA\n",
    "\n",
    "from rdflib import Graph, RDF, RDFS, Namespace, Literal, URIRef\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
    "sparql.setQuery(\"\"\"\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    SELECT ?cityName\n",
    "    WHERE { \n",
    "        <http://dbpedia.org/resource/Amsterdam> rdfs:label ?cityName \n",
    "    }\n",
    "\"\"\")\n",
    "sparql.setReturnFormat(JSON)\n",
    "results = sparql.query().convert()\n",
    "for result in results[\"results\"][\"bindings\"]:\n",
    "    print(result[\"cityName\"][\"value\"])  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For your convenience, we already wrote the following functions that might be useful to complete this task. \n",
    "In addition, we have loaded and printed the 'example-from-slides.ttl' dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@prefix ex: <http://example.com/kad/> .\n",
      "@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
      "\n",
      "ex:Netherlands a ex:Country ;\n",
      "    ex:contains ex:Ijsselmeer ;\n",
      "    ex:containsCity ex:Rotterdam ;\n",
      "    ex:hasCapital ex:Amsterdam ;\n",
      "    ex:hasName \"The Netherlands\" ;\n",
      "    ex:neighbours ex:Belgium .\n",
      "\n",
      "ex:hasCapital rdfs:range ex:Capital ;\n",
      "    rdfs:subPropertyOf ex:containsCity .\n",
      "\n",
      "ex:neighbours rdfs:subPropertyOf ex:closeBy .\n",
      "\n",
      "ex:Amsterdam a ex:Capital ;\n",
      "    ex:closeBy ex:Germany .\n",
      "\n",
      "ex:Belgium a ex:Country .\n",
      "\n",
      "ex:EuropeanCountry rdfs:subClassOf ex:Country .\n",
      "\n",
      "ex:Germany a ex:EuropeanCountry ;\n",
      "    ex:hasCapital ex:Berlin .\n",
      "\n",
      "ex:closeBy rdfs:domain ex:Location ;\n",
      "    rdfs:range ex:Location .\n",
      "\n",
      "ex:containsCity rdfs:domain ex:Country ;\n",
      "    rdfs:range ex:City ;\n",
      "    rdfs:subPropertyOf ex:contains .\n",
      "\n",
      "ex:Capital rdfs:subClassOf ex:City .\n",
      "\n",
      "ex:City rdfs:subClassOf ex:Location .\n",
      "\n",
      "ex:Country rdfs:subClassOf ex:Location .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from rdflib import Graph, RDF, Namespace, Literal, URIRef\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "\n",
    "# Loads the data from a certain file given as input in Turtle syntax into the Graph g  \n",
    "# -------------------------\n",
    "def load_graph(graph, filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        graph.parse(f, format='turtle')\n",
    "        \n",
    "\n",
    "# Prints a certain graph given as input in Turtle syntax\n",
    "# if your output shows byte string (ie, b'...') you must add '.decode()' to the print statements:\n",
    "#    print(myGraph.serialize(format='turtle').decode())\n",
    "# -------------------------\n",
    "def serialize_graph(myGraph):\n",
    "     print(myGraph.serialize(format='turtle'))\n",
    "        \n",
    "\n",
    "# Saves the Graph g in Turtle syntax to a certain file given as input\n",
    "# -------------------------\n",
    "def save_graph(myGraph, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        myGraph.serialize(filename, format='turtle')\n",
    "        \n",
    "    \n",
    "# Changes the namespace of a certain URI given as input to a DBpedia URI \n",
    "# Example: transformToDBR(\"http://example.com/kad2020/Amsterdam\") returns \"http://dbpedia.org/resource/Amsterdam\"\n",
    "# -------------------------\n",
    "def transformToDBR(uri):\n",
    "    if isinstance(uri, Literal):\n",
    "        # changes the literal to uppercase so that the object with the same name refers to an object and not the string\n",
    "        return uri.upper()\n",
    "    components = g.namespace_manager.compute_qname(uri)\n",
    "    return \"http://dbpedia.org/resource/%s\"%(components[2])\n",
    "\n",
    "# -------------------------\n",
    "\n",
    "g = Graph()\n",
    "load_graph(g, 'example-from-slides.ttl')\n",
    "serialize_graph(g)\n",
    "\n",
    "\n",
    "# Don't forget to run this cell before continuing the task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A: Write a SPARQL query that finds all the cities in the dataset\n",
    "\n",
    "As you cannot directly use class City, you will have to find those cities in the dataset (example-from-slides.ttl) using implicit information that can be deduced from the domain and ranges of the relations (e.g. things in a hasCapital relation are capitals and a capital is a city, etc.).\n",
    "\n",
    "Save all the cities returned from the SPARQL query into the empty set \"cities\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am going to use this function here too\n",
    "\n",
    "def strip(e):\n",
    "    # 'http://www.example.org/pizza' should become 'pizza'\n",
    "    string: str = \"\"\n",
    "    for char in e[::-1]:\n",
    "        if char == \"/\" or char == \"#\": # Appearantly 'or char == \"#\"' is not needed anymore\n",
    "            break\n",
    "        else:\n",
    "            string+= char\n",
    "    return string[::-1]\n",
    "\n",
    "# strip(\"http://www.example.org/pizza\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://example.com/kad/Rotterdam\n",
      "http://example.com/kad/Amsterdam\n",
      "http://example.com/kad/Berlin\n"
     ]
    }
   ],
   "source": [
    "cities = set()\n",
    "\n",
    "for s,p,o in g:\n",
    "    if \"city\" in strip(p).lower() or \"capital\" in strip(p).lower():\n",
    "        cities.add(o)\n",
    "\n",
    "    \n",
    "for city in cities:\n",
    "    print(city) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B: For each city, find from DBpedia its longitude & latitude, and its number of inhabitants (if available)\n",
    "\n",
    "Don't forget to adapt the namespace of the cities in your dataset when querying DBpedia, using the above function *transformToDBR(uri)*. Also note that namespaces should never use the *https* protocol.\n",
    "\n",
    "The empty graph h should only contain the triples extracted from DBpedia, but added to the URIs with the 'ex' namespace. \n",
    "An example of a triple in h is the following triple: \n",
    "       \n",
    "       ex:Amsterdam dbo:populationTotal \"872680\"^^xsd:nonNegativeInteger ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "PluginException",
     "evalue": "No plugin registered for (turtle, <class 'rdflib.query.ResultSerializer'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Downloads/Downloads/envs/newest_version/lib/python3.11/site-packages/rdflib/plugin.py:132\u001b[0m, in \u001b[0;36mget\u001b[0;34m(name, kind)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 132\u001b[0m     p: Plugin[PluginT] \u001b[39m=\u001b[39m _plugins[(name, kind)]\n\u001b[1;32m    133\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: ('turtle', <class 'rdflib.query.ResultSerializer'>)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPluginException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m h \u001b[39m=\u001b[39m Graph()\n\u001b[0;32m----> 3\u001b[0m serialize_graph(g\u001b[39m.\u001b[39;49mquery(\u001b[39m\"\"\"\u001b[39;49m\u001b[39mSELECT * WHERE \u001b[39;49m\u001b[39m{\u001b[39;49m\n\u001b[1;32m      4\u001b[0m \u001b[39m        ?s ?p ?o\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[39m}   LIMIT 10\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[39m        \u001b[39;49m\u001b[39m\"\"\"\u001b[39;49m))\n\u001b[1;32m      9\u001b[0m \u001b[39m# serialize_graph(h)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 17\u001b[0m, in \u001b[0;36mserialize_graph\u001b[0;34m(myGraph)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mserialize_graph\u001b[39m(myGraph):\n\u001b[0;32m---> 17\u001b[0m      \u001b[39mprint\u001b[39m(myGraph\u001b[39m.\u001b[39;49mserialize(\u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mturtle\u001b[39;49m\u001b[39m'\u001b[39;49m))\n",
      "File \u001b[0;32m~/Downloads/Downloads/envs/newest_version/lib/python3.11/site-packages/rdflib/query.py:318\u001b[0m, in \u001b[0;36mResult.serialize\u001b[0;34m(self, destination, encoding, format, **args)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"stolen wholesale from graph.serialize\"\"\"\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mrdflib\u001b[39;00m \u001b[39mimport\u001b[39;00m plugin\n\u001b[0;32m--> 318\u001b[0m serializer \u001b[39m=\u001b[39m plugin\u001b[39m.\u001b[39;49mget(\u001b[39mformat\u001b[39;49m, ResultSerializer)(\u001b[39mself\u001b[39m)\n\u001b[1;32m    319\u001b[0m \u001b[39mif\u001b[39;00m destination \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    320\u001b[0m     streamb: BytesIO \u001b[39m=\u001b[39m BytesIO()\n",
      "File \u001b[0;32m~/Downloads/Downloads/envs/newest_version/lib/python3.11/site-packages/rdflib/plugin.py:134\u001b[0m, in \u001b[0;36mget\u001b[0;34m(name, kind)\u001b[0m\n\u001b[1;32m    132\u001b[0m     p: Plugin[PluginT] \u001b[39m=\u001b[39m _plugins[(name, kind)]\n\u001b[1;32m    133\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[0;32m--> 134\u001b[0m     \u001b[39mraise\u001b[39;00m PluginException(\u001b[39m\"\u001b[39m\u001b[39mNo plugin registered for (\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (name, kind))\n\u001b[1;32m    135\u001b[0m \u001b[39mreturn\u001b[39;00m p\u001b[39m.\u001b[39mgetClass()\n",
      "\u001b[0;31mPluginException\u001b[0m: No plugin registered for (turtle, <class 'rdflib.query.ResultSerializer'>)"
     ]
    }
   ],
   "source": [
    "h = Graph()\n",
    "\n",
    "sparql.\n",
    "\n",
    "# serialize_graph(h)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C: Save your results\n",
    "\n",
    "- Merge the triples from example-from-slides.ttl with the information extracted from DBpedia. See the [documentation](https://rdflib.readthedocs.io/en/stable/merging.html) on how to accomplish this.\n",
    "- Save all these triples into a new file 'extended-example.ttl'. **It is not necessary to submit this file**\n",
    "- Print all triples in Turtle Syntax.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: (25 points)  Implement Basic Inferencing Rules "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the lecture we showed that the RDFS inference rules can be used to infer new knowledge. For example, infer class membership based on _rdfs:domain_ or infer relationships between subjects and objects based on _rdfs:subPropertyOf_. \n",
    "\n",
    "Create rules to inference class membership based on the RDF Schema language features \n",
    "*\tFor example: infer that an instance belongs to a class because of domain and range restrictions\n",
    "*\tFor example: infer that an instance belongs to a (super)class because it also belongs to a subclass\n",
    "\n",
    "We implemented the __rdfs2__ rule. You should implement the 5 following remaining rules:  \n",
    "\n",
    "*     (rdfs2) If G contains the triples (aaa rdfs:domain xxx.) and (uuu aaa yyy.)  then infer the triple (uuu rdf:type xxx.)\n",
    "*     (rdfs3) If G contains the triples (aaa rdfs:range xxx.) and (uuu aaa vvv.) then infer the triple (vvv rdf:type xxx .)\n",
    "*     (rdfs5) If G contains the triples (uuu rdfs:subPropertyOf vvv.) and (vvv rdfs:subPropertyOf xxx.) then infer the triple\n",
    "(uuu rdfs:subPropertyOf xxx.) \n",
    "*     (rdfs7) If G contains the triples (aaa rdfs:subPropertyOf bbb.) and (uuu aaa yyy.) then infer the triple (uuu bbb yyy) \n",
    "*     (rdfs9) If G contains the triples (uuu rdfs:subClassOf xxx.) and (vvv rdf:type uuu.) then infer the triple\n",
    " (vvv rdf:type xxx.)   -> this one was not mentioned in the lecture, but is a very important one. \n",
    "*     (rdfs11) If G contains the triples (uuu rdfs:subClassOf vvv.) and (vvv rdfs:subClassOf xxx.) then infer the triple\n",
    "(uuu rdfs:subClassOf xxx.)\n",
    "\n",
    "\n",
    "Run your rule reasoner on your knowledge graph. If you have implemented everything correctly, you should find exactly 17 inferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myRDFSreasoner(myGraph):\n",
    "    inferredTriples = 0\n",
    "    for sbj, prd, obj in myGraph:\n",
    "\n",
    "        # --- rdfs2 ---\n",
    "        if (prd.eq(URIRef(\"http://www.w3.org/2000/01/rdf-schema#domain\"))):\n",
    "            generator = myGraph.subject_objects(URIRef(sbj))\n",
    "            for s, o in generator:\n",
    "                inferredTriples += 1\n",
    "                print(\"(rdfs 2) \", s, \"rdf:type\", obj)\n",
    "        \n",
    "        \n",
    "        # --- rdfs3 ---\n",
    "\n",
    "        \n",
    "        \n",
    "        # --- rdfs5 ---\n",
    "\n",
    "        \n",
    "        \n",
    "        # --- rdfs7 ---\n",
    "\n",
    "         \n",
    "        \n",
    "        # --- rdfs9 ---\n",
    "\n",
    "        \n",
    "        \n",
    "        # --- rdfs11 ---\n",
    "        \n",
    "        \n",
    "    print(\"---------------------------------\")\n",
    "    print(\"Number of inferred triples:\", inferredTriples)\n",
    "    print(\"---------------------------------\")\n",
    "    \n",
    "myRDFSreasoner(g)  # test your reasoner\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: (20 points) Build your very own RDFS knowledge graph. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a small RDF Schema vocabulary in Turtle. You can choose your own domain (e.g. movies, geography, sports), as long as it hasn't been used as an example during the lectures. The following rules must be respected:\n",
    "*\tThe schema should define at least 4 classes, 4 properties, and 4 instances.\n",
    "*   The properties should be used to relate the instances (i.e., object-type relations)\n",
    "*\tThe instances should be members of at least one of the 4 defined classes\n",
    "*\tAll resources should have an rdfs:label attribute in a suitable language.\n",
    "\n",
    "You should use (at least) the following language features of RDF and RDFS:\n",
    "* \trdf:type (or 'a')\n",
    "* \trdfs:subClassOf\n",
    "* \trdfs:subPropertyOf\n",
    "* \trdfs:domain and rdfs:range\n",
    "*\trdfs:label\n",
    "\n",
    "Be sure to define the 'rdf:' and 'rdfs:' namespace prefixes for RDF and RDF Schema in your file (perhaps have a look at http://prefix.cc)\n",
    "\n",
    "For creating your vocabulary you should add the axioms directly (programatically) to your Knowledge Graph as you did last week. \n",
    "\n",
    "Play around with the inference rules you have created in the previous task to make sure that you added some implicit knowledge, that becomes \"visible\" via inferencing (this will be useful for the next task). \n",
    "\n",
    "Finally:\n",
    "- Add the knowledge you created into the RDFlib graph datastructure *myRDFSgraph*, \n",
    "- Print *myRDFSgraph* in Turtle so that we can check your \"design\"\n",
    "- Save *myRDFSgraph* into a new file 'myRDFSgraph.ttl' (it is not necessary to submit this file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myRDFSgraph = Graph()\n",
    "\n",
    "# Your code here.\n",
    "\n",
    "\n",
    "print(\"Now let's check what we can infer from your knowledge graph...\")\n",
    "print(\"The more rules you cover, the better!\")\n",
    "myRDFSreasoner(myRDFSgraph)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 (20 points) Compare local inferences with GraphDB results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload *myRDFSgraph.ttl* to GraphDB (check [the GraphDB tutorial](https://github.com/ucds-vu/knowledge-data-vu/blob/master/Tutorials/Preliminaries/tutorial-GraphDB.md) before starting to work with GraphDB).\n",
    "\n",
    "Formulate two different SPARQL queries, and write a Python code that executes these queries over your GraphDB SPARQL endpoint (check example of Task 1).\n",
    "\n",
    "**Each SPARQL query should return a _different type_ of inferred knowledge** (at least one triple that was not explicitly asserted in the graph).\n",
    "\n",
    "Specify below next to your query (using a comment '# ...') which type of RDFS rule is the GraphDB reasoner using to infer this answer (rdfs2, rdfs3, rdfs5, rdfs7, rdfs9, rdfs11). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get your GraphDB repository URL (setup -> repositories -> repository url) and assign it to the variable 'myEndpoint' below. \n",
    "# It should be similar to this: \n",
    "\n",
    "myEndpoint = \"http://127.0.0.1:7200/repositories/KnowledgeAndData\"  # KnowledgeAndData is the name of the repository\n",
    "sparql = SPARQLWrapper(myEndpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 1 - Specify which RDFS rule are you testing: \n",
    "\n",
    "# Check example of Task 1 on how to query remote SPARQL endpoints\n",
    "\n",
    "sparql.setQuery(\"\"\"\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 2 - Specify which RDFS rule are you testing: \n",
    "\n",
    "# Check example of Task 1 on how to query remote SPARQL endpoints\n",
    "\n",
    "sparql.setQuery(\"\"\"\n",
    "\n",
    "\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting the assignment\n",
    "\n",
    "Please submit this notebook (.ipynb) once you're finished with the assignment. It is not necessary to submit the created turtle files."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
